{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FIT5212 Assignment 2"
      ],
      "metadata": {
        "id": "nx8TtHRAlmWL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ps6spPTcd53",
        "outputId": "2fb06e81-6ffe-4c41-870c-e988747aa328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installations\n",
        "#!pip install numpy==1.23.5\n",
        "#!pip install implicit\n",
        "#!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olwdLeu0jABO",
        "outputId": "cf6d9411-9be9-474e-d030-20786ca597f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n",
            "Collecting scikit-surprise\n",
            "  Using cached scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.15.3)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2463298 sha256=a6e247efa3b5e522b968c0fb91f565b1267f87027949314722114421cae06c15\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n",
            "Collecting implicit\n",
            "  Downloading implicit-0.7.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from implicit) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.11/dist-packages (from implicit) (1.15.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from implicit) (4.67.1)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from implicit) (3.6.0)\n",
            "Downloading implicit-0.7.2-cp311-cp311-manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: implicit\n",
            "Successfully installed implicit-0.7.2\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.11/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.15.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "bDr6acSwlxcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scipy.sparse as sparse\n",
        "from implicit.als import AlternatingLeastSquares\n",
        "from surprise import SVD, Dataset, Reader, accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "xeXfek68cfgg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the train and test set"
      ],
      "metadata": {
        "id": "-VwrWfpvgCVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/Semi Structured/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/Semi Structured/test.csv\")"
      ],
      "metadata": {
        "id": "cwNgc42yclwG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ALS Method"
      ],
      "metadata": {
        "id": "maMxSuHsS6qu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 1"
      ],
      "metadata": {
        "id": "ZJwd70CD_s8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map user and product IDs to integers (required for matrix indexing)\n",
        "user_map = {user: idx for idx, user in enumerate(train['user_id'].unique())}\n",
        "product_map = {product: idx for idx, product in enumerate(train['product_id'].unique())}\n",
        "user_inv_map = {idx: user for user, idx in user_map.items()}\n",
        "product_inv_map = {idx: product for product, idx in product_map.items()}\n",
        "\n",
        "# Add integer IDs\n",
        "train['user_idx'] = train['user_id'].map(user_map)\n",
        "train['product_idx'] = train['product_id'].map(product_map)\n",
        "\n",
        "# Build a sparse matrix in item-user format\n",
        "rating_matrix = sparse.csr_matrix(\n",
        "    (train['rating'], (train['product_idx'], train['user_idx']))\n",
        ")\n",
        "\n",
        "# crafting the model and the specifications\n",
        "als_model = AlternatingLeastSquares(\n",
        "    factors=50,\n",
        "    regularization=0.1,\n",
        "    iterations=20,\n",
        "    use_gpu=False\n",
        ")\n",
        "als_model.fit(rating_matrix)\n",
        "\n",
        "# Map test users and products to internal IDs\n",
        "test['user_idx'] = test['user_id'].map(user_map)\n",
        "test['product_idx'] = test['product_id'].map(product_map)\n",
        "\n",
        "# Handle missing users/products gracefully\n",
        "test['user_idx'] = test['user_idx'].fillna(-1).astype(int)\n",
        "test['product_idx'] = test['product_idx'].fillna(-1).astype(int)\n",
        "\n",
        "# Get user and item factors\n",
        "user_factors = als_model.user_factors\n",
        "item_factors = als_model.item_factors\n",
        "\n",
        "num_users = user_factors.shape[0]\n",
        "num_items = item_factors.shape[0]\n",
        "\n",
        "# Predict rating using dot product of latent vectors\n",
        "def predict_score(row):\n",
        "    u = row['user_idx']\n",
        "    p = row['product_idx']\n",
        "    if u < 0 or u >= num_users or p < 0 or p >= num_items:\n",
        "        return 3.0  # fallback value\n",
        "    return np.dot(user_factors[u], item_factors[p])\n",
        "\n",
        "test['rating'] = test.apply(predict_score, axis=1)\n",
        "test['rating'] = test['rating'].clip(1, 5).round(2)\n",
        "\n",
        "submission = test[['ID', 'rating']]\n",
        "submission.to_csv(\"/content/drive/MyDrive/Semi Structured/ALS.csv\", index=False)"
      ],
      "metadata": {
        "id": "bn5tTc6nc5J0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVD"
      ],
      "metadata": {
        "id": "WeUbqUrCS_ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We only need these columns for the model\n",
        "data = train[['user_id', 'product_id', 'rating']]\n",
        "\n",
        "# Define the rating scale\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Load data into Surprise's format\n",
        "surprise_data = Dataset.load_from_df(data, reader)\n",
        "\n",
        "# Split for validation\n",
        "trainset, valset = train_test_split(surprise_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "svd_model = SVD()\n",
        "svd_model.fit(trainset)\n",
        "\n",
        "# Evaluate on validation set\n",
        "predictions = svd_model.test(valset)\n",
        "rmse = accuracy.rmse(predictions)\n",
        "print(f\"Validation RMSE: {rmse:.4f}\")\n",
        "\n",
        "test2 = test.copy()\n",
        "\n",
        "# Predict using the trained model\n",
        "test2['rating'] = test2.apply(\n",
        "    lambda row: svd_model.predict(row['user_id'], row['product_id']).est,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Clip predictions to rating scale\n",
        "test2['rating'] = test2['rating'].clip(1, 5).round(2)\n",
        "\n",
        "submission = test2[['ID', 'rating']]\n",
        "submission.to_csv(\"/content/drive/MyDrive/Semi Structured/SVD.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnE5tnwcf0rg",
        "outputId": "2e0fff09-a171-432f-b2b3-4051fbf01eda"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.9366\n",
            "Validation RMSE: 0.9366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the hyperparameter options\n",
        "param_grid = {\n",
        "    'n_factors': [50, 100],\n",
        "    'lr_all': [0.002, 0.005],\n",
        "    'reg_all': [0.02, 0.1]\n",
        "}\n",
        "\n",
        "# Perform the grid search\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
        "gs.fit(surprise_data)\n",
        "\n",
        "print(\"Best RMSE:\", gs.best_score['rmse'])\n",
        "print(\"Best Params:\", gs.best_params['rmse'])\n",
        "\n",
        "# Retrain best model on full data\n",
        "best_model = gs.best_estimator['rmse']\n",
        "trainset = surprise_data.build_full_trainset()\n",
        "best_model.fit(trainset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwQSlTclktqG",
        "outputId": "39f25309-1c3d-49e0-d131-9d2fac9b3e54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE: 0.9399456757870149\n",
            "Best Params: {'n_factors': 100, 'lr_all': 0.005, 'reg_all': 0.1}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7970247a9410>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test3 = test.copy()\n",
        "# Predict using the best model\n",
        "test3['rating'] = test3.apply(\n",
        "    lambda row: best_model.predict(row['user_id'], row['product_id']).est,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Clip to valid rating range\n",
        "test3['rating'] = test3['rating'].clip(1, 5).round(2)\n",
        "print(\"Best RMSE:\", gs.best_score['rmse'])\n",
        "print(\"Best Params:\", gs.best_params['rmse'])\n",
        "\n",
        "# Save CSV with required format\n",
        "submission = test3[['ID', 'rating']]\n",
        "submission.to_csv(\"/content/drive/MyDrive/Semi Structured/svd_optimized.csv\", index=False)"
      ],
      "metadata": {
        "id": "6R1A53u1BVSN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further SVD Parameter Experiments"
      ],
      "metadata": {
        "id": "2wfwYE4Md-VD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_factors': [100, 150],\n",
        "    'lr_all': [0.005, 0.007],\n",
        "    'reg_all': [0.1, 0.12],\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
        "gs.fit(surprise_data)\n",
        "\n",
        "# Retrain best model on full data\n",
        "best_model = gs.best_estimator['rmse']\n",
        "trainset = surprise_data.build_full_trainset()\n",
        "best_model.fit(trainset)\n",
        "\n",
        "test7 = test.copy()\n",
        "# Predict using the best model\n",
        "test7['rating'] = test7.apply(\n",
        "    lambda row: best_model.predict(row['user_id'], row['product_id']).est,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Clip to valid rating range\n",
        "test7['rating'] = test7['rating'].clip(1, 5).round(2)\n",
        "\n",
        "# Save CSV with required format\n",
        "submission = test7[['ID', 'rating']]\n",
        "submission.to_csv(\"/content/drive/MyDrive/Semi Structured/svd_optimized4.csv\", index=False)\n",
        "print(\"Best RMSE:\", gs.best_score['rmse'])\n",
        "print(\"Best Params:\", gs.best_params['rmse'])"
      ],
      "metadata": {
        "id": "emygXH0MyQr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_factors': [150, 160, 175],\n",
        "    'lr_all': [0.006, 0.007, 0.008],\n",
        "    'reg_all': [0.09, 0.1],\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
        "gs.fit(surprise_data)\n",
        "\n",
        "# Retrain best model on full data\n",
        "best_model = gs.best_estimator['rmse']\n",
        "trainset = surprise_data.build_full_trainset()\n",
        "best_model.fit(trainset)\n",
        "\n",
        "test7 = test.copy()\n",
        "# Predict using the best model\n",
        "test7['rating'] = test7.apply(\n",
        "    lambda row: best_model.predict(row['user_id'], row['product_id']).est,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Clip to valid rating range\n",
        "test7['rating'] = test7['rating'].clip(1, 5).round(2)\n",
        "\n",
        "# Save CSV with required format\n",
        "submission = test7[['ID', 'rating']]\n",
        "submission.to_csv(\"/content/drive/MyDrive/Semi Structured/svd_optimized4.csv\", index=False)\n",
        "print(\"Best RMSE:\", gs.best_score['rmse'])\n",
        "print(\"Best Params:\", gs.best_params['rmse'])"
      ],
      "metadata": {
        "id": "sxSjuzJooZ4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_factors': [175, 185, 195],\n",
        "    'lr_all': [0.008, 0.009, 0.01],\n",
        "    'reg_all': [0.095, 0.1],\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
        "gs.fit(surprise_data)\n",
        "\n",
        "# Retrain best model on full data\n",
        "best_model = gs.best_estimator['rmse']\n",
        "trainset = surprise_data.build_full_trainset()\n",
        "best_model.fit(trainset)\n",
        "\n",
        "test7 = test.copy()\n",
        "# Predict using the best model\n",
        "test7['rating'] = test7.apply(\n",
        "    lambda row: best_model.predict(row['user_id'], row['product_id']).est,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Clip to valid rating range\n",
        "test7['rating'] = test7['rating'].clip(1, 5).round(2)\n",
        "\n",
        "# Save CSV with required format\n",
        "submission = test7[['ID', 'rating']]\n",
        "submission.to_csv(\"/content/drive/MyDrive/Semi Structured/svd_optimized5.csv\", index=False)\n",
        "\n",
        "print(\"Best RMSE:\", gs.best_score['rmse'])\n",
        "print(\"Best Params:\", gs.best_params['rmse'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDDO1AFbU1Kx",
        "outputId": "41b16469-7b0a-4c1e-c2c3-279f1cb010d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE: 0.9284535318463298\n",
            "Best Params: {'n_factors': 185, 'lr_all': 0.01, 'reg_all': 0.095}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_factors': [190, 191, 192, 193, 194],\n",
        "    'lr_all': [0.015, 0.016, 0.017, 0.018],\n",
        "    'reg_all': [0.095],\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
        "gs.fit(surprise_data)\n",
        "\n",
        "# Retrain best model on full data\n",
        "best_model = gs.best_estimator['rmse']\n",
        "trainset = surprise_data.build_full_trainset()\n",
        "best_model.fit(trainset)\n",
        "\n",
        "test7 = test.copy()\n",
        "# Predict using the best model\n",
        "test7['rating'] = test7.apply(\n",
        "    lambda row: best_model.predict(row['user_id'], row['product_id']).est,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Clip to valid rating range\n",
        "test7['rating'] = test7['rating'].clip(1, 5).round(2)\n",
        "\n",
        "# Save CSV with required format\n",
        "submission = test7[['ID', 'rating']]\n",
        "submission.to_csv(\"/content/drive/MyDrive/Semi Structured/svd_optimized7.csv\", index=False)\n",
        "\n",
        "print(\"Best RMSE:\", gs.best_score['rmse'])\n",
        "print(\"Best Params:\", gs.best_params['rmse'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHtet1Nqs1FN",
        "outputId": "76b086d1-9c8b-4e3d-ef48-a54a2a044cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE: 0.9192523465540559\n",
            "Best Params: {'n_factors': 193, 'lr_all': 0.018, 'reg_all': 0.095}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_factors': [180, 185, 190],\n",
        "    'lr_all': [0.01, 0.012, 0.015],\n",
        "    'reg_all': [0.095],\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
        "gs.fit(surprise_data)\n",
        "\n",
        "# Retrain best model on full data\n",
        "best_model = gs.best_estimator['rmse']\n",
        "trainset = surprise_data.build_full_trainset()\n",
        "best_model.fit(trainset)\n",
        "\n",
        "test7 = test.copy()\n",
        "# Predict using the best model\n",
        "test7['rating'] = test7.apply(\n",
        "    lambda row: best_model.predict(row['user_id'], row['product_id']).est,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Clip to valid rating range\n",
        "test7['rating'] = test7['rating'].clip(1, 5).round(2)\n",
        "\n",
        "# Save CSV with required format\n",
        "submission = test7[['ID', 'rating']]\n",
        "submission.to_csv(\"/content/drive/MyDrive/Semi Structured/svd_optimized6.csv\", index=False)\n",
        "\n",
        "print(\"Best RMSE:\", gs.best_score['rmse'])\n",
        "print(\"Best Params:\", gs.best_params['rmse'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVxjF-J0mFnq",
        "outputId": "0a2a07d3-3c0d-4fec-cd2d-3deefd342175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE: 0.9214975483593362\n",
            "Best Params: {'n_factors': 190, 'lr_all': 0.015, 'reg_all': 0.095}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVD Filtered"
      ],
      "metadata": {
        "id": "gWmEiHUPTYz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter out the unhelpful reviews\n",
        "filtered_df = train[train['votes'] > 0]"
      ],
      "metadata": {
        "id": "o57Hy9wtTEdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We only need these columns for the model\n",
        "data = filtered_df[['user_id', 'product_id', 'rating']]\n",
        "\n",
        "# Define the rating scale\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Load data into Surprise's format\n",
        "surprise_data = Dataset.load_from_df(data, reader)\n",
        "\n",
        "# Split for validation\n",
        "trainset, valset = train_test_split(surprise_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "svd_model = SVD()\n",
        "svd_model.fit(trainset)\n",
        "\n",
        "# Evaluate on validation set\n",
        "predictions = svd_model.test(valset)\n",
        "rmse = accuracy.rmse(predictions)\n",
        "print(f\"Validation RMSE: {rmse:.4f}\")\n",
        "\n",
        "param_grid = {\n",
        "    'n_factors': [170, 185, 193],\n",
        "    'lr_all': [0.012, 0.015, 0.018],\n",
        "    'reg_all': [0.095],\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
        "gs.fit(surprise_data)\n",
        "\n",
        "# Retrain best model on full data\n",
        "best_model = gs.best_estimator['rmse']\n",
        "trainset = surprise_data.build_full_trainset()\n",
        "best_model.fit(trainset)\n",
        "\n",
        "print(\"Best RMSE:\", gs.best_score['rmse'])\n",
        "print(\"Best Params:\", gs.best_params['rmse'])\n",
        "\n",
        "test4 = test.copy()\n",
        "# Predict using the best model\n",
        "test4['rating'] = test4.apply(\n",
        "    lambda row: best_model.predict(row['user_id'], row['product_id']).est,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Clip to valid rating range\n",
        "test4['rating'] = test4['rating'].clip(1, 5).round(2)\n",
        "\n",
        "# Save CSV with required format\n",
        "submission = test4[['ID', 'rating']]\n",
        "submission.to_csv(\"/content/drive/MyDrive/Semi Structured/svd_optimized2.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikemDKNVOKLa",
        "outputId": "b7d0e0ef-6d98-4454-e3d1-d58ab71a492a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.9593\n",
            "Validation RMSE: 0.9593\n",
            "Best RMSE: 0.9517115791315832\n",
            "Best Params: {'n_factors': 150, 'lr_all': 0.009, 'reg_all': 0.095}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVD Weighted"
      ],
      "metadata": {
        "id": "e5ZrkkkLWxIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_df = train.copy()\n",
        "weighted_df['confidence'] = 1 + train['helpful_votes'] / (train['votes'] + 1)\n",
        "weighted_df['adjusted_rating'] = weighted_df['rating'] * weighted_df['confidence']"
      ],
      "metadata": {
        "id": "eYXJ2MZgWalU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We only need these columns for the model\n",
        "data = weighted_df[['user_id', 'product_id', 'adjusted_rating']]\n",
        "\n",
        "# Define the rating scale\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Load data into Surprise's format\n",
        "surprise_data = Dataset.load_from_df(data, reader)\n",
        "\n",
        "# Split for validation\n",
        "trainset, valset = train_test_split(surprise_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "svd_model = SVD()\n",
        "svd_model.fit(trainset)\n",
        "\n",
        "# Evaluate on validation set\n",
        "predictions = svd_model.test(valset)\n",
        "rmse = accuracy.rmse(predictions)\n",
        "print(f\"Validation RMSE: {rmse:.4f}\")\n",
        "\n",
        "param_grid = {\n",
        "    'n_factors': [100, 150, 193],\n",
        "    'lr_all': [0.012, 0.015, 0.018],\n",
        "    'reg_all': [0.095],\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
        "gs.fit(surprise_data)\n",
        "\n",
        "print(\"Best RMSE:\", gs.best_score['rmse'])\n",
        "print(\"Best Params:\", gs.best_params['rmse'])\n",
        "\n",
        "# Retrain best model on full data\n",
        "best_model = gs.best_estimator['rmse']\n",
        "trainset = surprise_data.build_full_trainset()\n",
        "best_model.fit(trainset)\n",
        "\n",
        "test5 = test.copy()\n",
        "# Predict using the best model\n",
        "test5['rating'] = test5.apply(\n",
        "    lambda row: best_model.predict(row['user_id'], row['product_id']).est,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Clip to valid rating range\n",
        "test5['rating'] = test5['rating'].clip(1, 5).round(2)\n",
        "\n",
        "# Save CSV with required format\n",
        "submission = test5[['ID', 'rating']]\n",
        "submission.to_csv(\"/content/drive/MyDrive/Semi Structured/svd_optimized3.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDwdXPsPTp7a",
        "outputId": "1db4e452-398c-4400-ecbb-e6a42aad13e9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 2.6053\n",
            "Validation RMSE: 2.6053\n",
            "Best RMSE: 2.602923130852104\n",
            "Best Params: {'n_factors': 100, 'lr_all': 0.018, 'reg_all': 0.095}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF"
      ],
      "metadata": {
        "id": "9T4ry_6OcHzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(train['product_name'])\n",
        "\n",
        "\n",
        "# Fit nearest neighbors model\n",
        "nn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
        "nn_model.fit(tfidf_matrix)\n",
        "\n",
        "product_idx_map = {pid: idx for idx, pid in enumerate(train['product_id'])}\n",
        "idx_product_map = {idx: pid for pid, idx in product_idx_map.items()}\n",
        "\n",
        "top_products = train['product_id'].value_counts().head(20000).index\n",
        "top_indices = [product_idx_map[pid] for pid in top_products if pid in product_idx_map]\n",
        "\n",
        "# Filter TF-IDF matrix to just top products\n",
        "tfidf_subset = tfidf_matrix[top_indices]\n",
        "\n",
        "# Now only compute neighbors for these\n",
        "distances, indices = nn_model.kneighbors(tfidf_subset)\n",
        "\n",
        "# Precompute similar product IDs (excluding self)\n",
        "similar_items_cache = {}\n",
        "# distances, indices = nn_model.kneighbors(tfidf_matrix)\n",
        "\n",
        "for i, row in enumerate(indices):\n",
        "    pid = idx_product_map[top_indices[i]]  # Correct product ID from original index\n",
        "    similar_ids = [idx_product_map[idx] for idx in row[1:] if idx in idx_product_map]\n",
        "    similar_items_cache[pid] = similar_ids\n",
        "\n",
        "# Precompute average rating per product\n",
        "product_ratings = train.groupby('product_id')['rating'].mean().to_dict()\n",
        "global_avg = train['rating'].mean()\n",
        "\n",
        "def fast_content_predict(product_id):\n",
        "    similar_ids = similar_items_cache.get(product_id, [])\n",
        "    ratings = [product_ratings.get(pid) for pid in similar_ids if pid in product_ratings]\n",
        "    return round(np.mean(ratings) if ratings else global_avg, 2)\n"
      ],
      "metadata": {
        "id": "ZANuFCdJXEPl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test6 = test.copy()\n",
        "test6['rating'] = test6['product_id'].apply(fast_content_predict)\n",
        "test6['rating'] = test6['rating'].clip(1, 5)\n",
        "\n",
        "# Save CSV with required format\n",
        "submission = test6[['ID', 'rating']]\n",
        "submission.to_csv(\"/content/drive/MyDrive/Semi Structured/tf_idf.csv\", index=False)"
      ],
      "metadata": {
        "id": "p9is5T661zcA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "qpqnFa5Elfte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode user_id and product_id\n",
        "user_encoder = LabelEncoder()\n",
        "product_encoder = LabelEncoder()\n",
        "\n",
        "train['user_enc'] = user_encoder.fit_transform(train['user_id'])\n",
        "train['product_enc'] = product_encoder.fit_transform(train['product_id'])\n",
        "\n",
        "# Compute helpful_ratio with smoothing\n",
        "train['helpful_ratio'] = train['helpful_votes'] / (train['votes'] + 1)\n",
        "\n",
        "# Basic features\n",
        "features = ['user_enc', 'product_enc', 'votes', 'helpful_votes', 'helpful_ratio']\n",
        "X = train[features]\n",
        "y = train['rating']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train XGBoost model\n",
        "model = xgb.XGBRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    objective='reg:squarederror',\n",
        "    verbosity=0\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Load test set\n",
        "test['product_name'] = test['product_name'].fillna(\"\")\n",
        "\n",
        "# Encode using trained encoders\n",
        "test['user_enc'] = test['user_id'].map(lambda x: user_encoder.transform([x])[0] if x in user_encoder.classes_ else -1)\n",
        "test['product_enc'] = test['product_id'].map(lambda x: product_encoder.transform([x])[0] if x in product_encoder.classes_ else -1)\n",
        "test['votes'] = test.get('votes', 0)\n",
        "test['helpful_votes'] = test.get('helpful_votes', 0)\n",
        "test['helpful_ratio'] = test['helpful_votes'] / (test['votes'] + 1)\n",
        "\n",
        "# Replace unknown encodings with medians\n",
        "median_user = int(train['user_enc'].median())\n",
        "median_product = int(train['product_enc'].median())\n",
        "test['user_enc'] = test['user_enc'].replace(-1, median_user)\n",
        "test['product_enc'] = test['product_enc'].replace(-1, median_product)\n",
        "\n",
        "# Predict ratings\n",
        "X_test = test[features]\n",
        "test['rating'] = model.predict(X_test)\n",
        "test['rating'] = test['rating'].clip(1, 5).round(2)\n",
        "\n",
        "# Export CSV\n",
        "submission = test[['ID', 'rating']]\n",
        "submission.to_csv(\"/content/drive/MyDrive/Semi Structured/xgboost.csv\", index=False)"
      ],
      "metadata": {
        "id": "oqqeKsn_hGZ1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reimport a different version of train_test_split that works\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Encode user_id and product_id\n",
        "user_encoder = LabelEncoder()\n",
        "product_encoder = LabelEncoder()\n",
        "\n",
        "train['user_enc'] = user_encoder.fit_transform(train['user_id'])\n",
        "train['product_enc'] = product_encoder.fit_transform(train['product_id'])\n",
        "\n",
        "# Compute helpful_ratio with smoothing\n",
        "train['helpful_ratio'] = train['helpful_votes'] / (train['votes'] + 1)\n",
        "\n",
        "# Calculate the average rating a user given across all products\n",
        "user_avg_rating = train.groupby('user_id')['rating'].mean().to_dict()\n",
        "\n",
        "# Calculate how many ratings a user has made\n",
        "user_rating_count = train['user_id'].value_counts().to_dict()\n",
        "\n",
        "# Calculate the average rating a product has received from users\n",
        "product_avg_rating = train.groupby('product_id')['rating'].mean().to_dict()\n",
        "\n",
        "# Calculate how many times a product has been rated\n",
        "product_rating_count = train['product_id'].value_counts().to_dict()\n",
        "\n",
        "# Map the average data to the training dataset\n",
        "train['user_avg_rating'] = train['user_id'].map(user_avg_rating)\n",
        "train['user_rating_count'] = train['user_id'].map(user_rating_count)\n",
        "train['product_avg_rating'] = train['product_id'].map(product_avg_rating)\n",
        "train['product_rating_count'] = train['product_id'].map(product_rating_count)\n",
        "\n",
        "# Define the new features\n",
        "features = [\n",
        "    'user_enc', 'product_enc',\n",
        "    'votes', 'helpful_votes', 'helpful_ratio',\n",
        "    'user_avg_rating', 'user_rating_count',\n",
        "    'product_avg_rating', 'product_rating_count'\n",
        "]\n",
        "X = train[features]\n",
        "y = train['rating']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# define the hyperparameter range\n",
        "param_range = {\n",
        "    \"n_estimators\": randint(100, 300),\n",
        "    \"max_depth\": randint(6, 8),\n",
        "    \"learning_rate\": uniform(0.01, 0.2),\n",
        "    \"subsample\": uniform(0.6, 0.4),\n",
        "    \"colsample_bytree\": uniform(0.6, 0.4),\n",
        "    \"reg_alpha\": uniform(0, 0.5),\n",
        "    \"reg_lambda\": uniform(0.5, 1.5)\n",
        "}\n",
        "\n",
        "# perform the search to see which config is the best\n",
        "search = RandomizedSearchCV(\n",
        "    estimator=xgb.XGBRegressor(objective='reg:squarederror', verbosity=0),\n",
        "    param_distributions=param_range,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    n_iter=10,\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "search.fit(X_train, y_train)\n",
        "model = search.best_estimator_\n",
        "\n",
        "# Load test set\n",
        "test['product_name'] = test['product_name'].fillna(\"\")\n",
        "\n",
        "# Encode using trained encoders\n",
        "test['user_enc'] = test['user_id'].map(lambda x: user_encoder.transform([x])[0] if x in user_encoder.classes_ else -1)\n",
        "test['product_enc'] = test['product_id'].map(lambda x: product_encoder.transform([x])[0] if x in product_encoder.classes_ else -1)\n",
        "test['votes'] = test.get('votes', 0)\n",
        "test['helpful_votes'] = test.get('helpful_votes', 0)\n",
        "test['helpful_ratio'] = test['helpful_votes'] / (test['votes'] + 1)\n",
        "\n",
        "test['user_avg_rating'] = test['user_id'].map(user_avg_rating)\n",
        "test['user_rating_count'] = test['user_id'].map(user_rating_count)\n",
        "test['product_avg_rating'] = test['product_id'].map(product_avg_rating)\n",
        "test['product_rating_count'] = test['product_id'].map(product_rating_count)\n",
        "\n",
        "\n",
        "# Replace unknown encodings with medians\n",
        "median_user = int(train['user_enc'].median())\n",
        "median_product = int(train['product_enc'].median())\n",
        "test['user_enc'] = test['user_enc'].replace(-1, median_user)\n",
        "test['product_enc'] = test['product_enc'].replace(-1, median_product)\n",
        "\n",
        "# Predict ratings\n",
        "X_test = test[features]\n",
        "test['rating'] = model.predict(X_test)\n",
        "test['rating'] = test['rating'].clip(1, 5).round(2)\n",
        "\n",
        "# Export CSV\n",
        "submission = test[['ID', 'rating']]\n",
        "submission.to_csv(\"/content/drive/MyDrive/Semi Structured/xgboost2.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVXYQWV40KOw",
        "outputId": "68b6a7f3-19ec-4881-f6b4-1396b268de6e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tSSR8GkV4VvP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}